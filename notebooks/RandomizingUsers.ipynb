{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Randomizing Users: Two Methods Compared\n",
    "=======================================\n",
    "\n",
    "Tommy Guy\n",
    "\n",
    "Last Edited: August 28, 2016"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At KDD 2016, Netflix published a paper called [Improving the Sensitivity of Online Controlled Studies](http://www.kdd.org/kdd2016/subtopic/view/improving-the-sensitivity-of-online-controlled-experiments-case-studies-at-) that among other things explains how Netflix randomizes users for controlled experiments.\n",
    "\n",
    "The thing is, I've never heard of anyone using their method! Most systems including the platform on [my team](http://www.exp-platform.com) use a stateless approach based on hashing that optimizes for efficient, repeatable assignment. Netflix uses a queue-based system that emphasizes balanced assignments but at the expense of storage and complexity.\n",
    "\n",
    "In this post, I'll make a psuedo-implementation of each approach and discuss the tradeoffs inherent in each. I'm pretty convinced I don't want to take Netflix's approach, but you can be your own judge."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, Let's Design Some Experiments\n",
    "---------------------------\n",
    "\n",
    "To finish setting the stage, each experiment has two or more buckets that correspond to user experiences. Typically, one of these buckets is the \"control\" or existing experience. An experiment is really a set of buckets of a fractional size of the total population. The variable `experiments` below is a very basic schematic of a set of experiments.\n",
    "\n",
    "We assume that the system will handle potentially hundreds of experiments and tens of millions of users, though not every experiment will be applicable to every user at any given time. A few reasons why an experiment wouldn't apply to a particular user include the experiment uses a filtered subset of traffic (say, en-gb only) or the experiment is set up to be mutually exclusive of another experiment. The latter case happens when we want to test two potentially interacting ideas and ensure that a user isn't exposed to the cross product of possible outcomes simultaneously. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_total_buckets = 100\n",
    "        \n",
    "experiments = {\n",
    "    'ChangeButton': {\n",
    "        'buckets': [  # describe the set of available buckets.\n",
    "            {'name': 'blue', 'allocation': .25},  # note that only half of users are in buckets.\n",
    "            {'name': 'red', 'allocation': .25}\n",
    "        ],\n",
    "        'filters': {  # describe any filters that apply to the experiment. These must be knowable at assignment time.\n",
    "            'locale': 'en-us'\n",
    "        },\n",
    "        'id': 'ChangeButton'\n",
    "    },\n",
    "    'ChangeLogo': {\n",
    "        'buckets': [  # describe the set of available buckets.\n",
    "            {'name': 'stickfigure', 'size': .10},\n",
    "            {'name': 'professional', 'size': .10}\n",
    "        ],\n",
    "        'filters': {  # describe any filters that apply to the experiment. These must be knowable at assignment time.\n",
    "            'locale': 'en-us'\n",
    "        },\n",
    "        'id': 'ChangeLogo'\n",
    "    }\n",
    "}\n",
    "\n",
    "#\n",
    "# Set up a very basic base randomizer. Subclasses will override _randomize_user.\n",
    "#\n",
    "class BaseExperimentRandomizer(object):\n",
    "\n",
    "    def filters_apply(self, user, experiment):\n",
    "        filters = experiment['filters']\n",
    "        return all([user.get(k) == v for k, v in filters.items()])\n",
    "    \n",
    "    def assign_user(self, user, experiment_id):\n",
    "        experiment = experiments[experiment_id]\n",
    "        if not self.filters_apply(user, experiment):\n",
    "            return 'noop'\n",
    "        return self._randomize_user(user['id'], experiment)\n",
    "    \n",
    "    def _randomize_user(self, user_id, experiment):\n",
    "        # Dumb case simply returns the first bucket. \n",
    "        # http://xkcd.com/221/\n",
    "        return experiment[0]['name']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The gist is that experiments define a set of filters and a set of buckets. Each bucket has a name and a size. To tell if a user is exposed to an experiment, we check whether the filters apply then use a randomizing function. Our initial randomization is [pretty dumb](http://xkcd.com/221/) and we'll improve it below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to Judge a Randomization System\n",
    "-----------------------------------\n",
    "\n",
    "Here are the criteria I will use to judge the two approaches.\n",
    "\n",
    "**Must haves**\n",
    "* Repeatability: A user will be in the same bucket for a given experiment provided the experiment's allocation is stable.\n",
    "* Ramp Up and Ramp Down: We need to be able to quickly change allocations including killing experiments that show problems.\n",
    "* Experiment Exclusion: We can configure two experiments to not overlap if we want. A user in treatment or control for experiment 1 will not be in experiment 2.\n",
    "\n",
    "**Statistical Efficiency**\n",
    "* Statistical Dependability: Does the system reliably produce unbiased, balanced allocations of users?\n",
    "* Stratification: Is stratified sampling possible? (The original topic of Netflix's paper).\n",
    "\n",
    "The first three requirements are considered table stakes: we have to be able to keep a consistent experience. What I'm calling statistical efficiency is really judging whether the system can avoid accidentally biasing the random split. We can usually detect when that bias occurs (which I'll discuss below) but such failure require an experiment rerun which reduces our efficiency. Therefore a system where more random allocations are usable in production would be better.\n",
    "\n",
    "\n",
    "Given our criteria, let's introduce the two systems!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hash and Bucket Randomization\n",
    "-----------------------------\n",
    "\n",
    "The standard algorithm for randomizing users was introduced in several papers including papers from Google and Microsoft (todo links). Assume every user has a unique, persistent identifier that is known at assignment time. Use a series of salted hashes and identifier to determine a user's assignment. The first example below doesn't handle exclusion but introduces the hashing system. The second example is the full monty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from itertools import accumulate\n",
    "\n",
    "class SimpleHashAndBucketRandomizer(BaseExperimentRandomizer):\n",
    "    # Does not do experiment exclusion.\n",
    "    \n",
    "    def _randomize_user(self, user_id, experiment):\n",
    "        salted_user = str(user_id) + experiment['id']\n",
    "        hash_value = hash(salted_user) % num_total_buckets\n",
    "        \n",
    "        buckets = experiment['buckets']\n",
    "        cumulative_buckets = list(accumulate([bucket['allocation'] * num_total_buckets for bucket in buckets]))\n",
    "        bucket_index = sum([bb < hash_value for bb in cumulative_buckets])\n",
    "        if bucket_index == len(buckets):\n",
    "            return 'noop'  # User isn't in experiment\n",
    "        return buckets[bucket_index]['name']\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*One word of caution* I'm using python's built-in hash function here because hash functions aren't my focus. Don't do that in produciton. At Microsoft, we use Spooky Hash, and we've got a paper arguing that in more complicated setups involving multiple overlapping experiments, it's the only hash function we found that correctly orthogonalizes experiments to prevent interaction effects in unrelated experiments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Repeatability**\n",
    "HashAndBucket randomization is a *stateless* randomizer: we store state about active experiments but we can recompute a user's information on the fly from the stable user id.\n",
    "\n",
    "**Rampup and Shutdown**\n",
    "Since the system doesn't persist user assignments, one can change allocation and it will be immediately reflected. If a user is in treatment \"ChangeButton\" and we decide to shut off that experiment, the very next call for that user will automatically move them into \"noop\". \n",
    "\n",
    "**Experiment Exclusion**\n",
    "If we want to run two experiments such that a user can't be in both, we use the same hash salt on both experiments, but we assign the experiments to non-overlapping buckets. If we have an experiment with 25% of users in each bucket and another with 10% in each bucket, we use a single salt and assign 50 buckets to each experiment. In the implementation below, we also introduce a per-experiment salt, which I'll come back to later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Put our two experiments on a single salt.\n",
    "hashes = {\n",
    "    'UISalt1': {\n",
    "        'salt': 'abracadabra',\n",
    "        'current_buckets': [\n",
    "            {'name': 'ChangeButton', 'allocation': .50},\n",
    "            {'name': 'ChangeLogo', 'allocation': .20},\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Add salt to every experiment.\n",
    "for key in experiments.keys():\n",
    "    experiments[key][\"salt\"] = \"UISalt1\"\n",
    "\n",
    "# Define a within-experiment allocation (essentially, make experiment use the whole hash.)\n",
    "experiments_sans_noop = {\n",
    "    'ChangeButton': {\n",
    "        'buckets': [\n",
    "            {'name': 'blue', 'allocation': .50},\n",
    "            {'name': 'red', 'allocation': .50}\n",
    "        ],\n",
    "        'id': 'ChangeButton'\n",
    "    },\n",
    "    'ChangeLogo': {\n",
    "        'buckets': [\n",
    "            {'name': 'stickfigure', 'allocation': .50},\n",
    "            {'name': 'professional', 'allocation': .50}\n",
    "        ],\n",
    "        'id': 'ChangeLogo'\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class HashAndBucketRandomizer(BaseExperimentRandomizer):\n",
    "    # Does not do experiment exclusion.\n",
    "    \n",
    "    def _do_randomization(self, user_id, salt, allocation):\n",
    "        # Helper function that basically does the work in SimpleHashAndBucketRandomizer.\n",
    "        # We need it twice in this system: once to pick an experiment and once to pick a bucket in \n",
    "        # The experiment.\n",
    "        salted_user = str(user_id) + salt\n",
    "        hash_value = hash(salted_user) % num_total_buckets\n",
    "        cumulative_buckets = list(accumulate([bucket['allocation'] * num_total_buckets for bucket in allocation]))\n",
    "        bucket_index = sum([bb <= hash_value for bb in cumulative_buckets])\n",
    "        if bucket_index == len(allocation):\n",
    "            return 'noop2'  # User isn't in experiment. Should never show up.\n",
    "        return allocation[bucket_index]['name']\n",
    "    \n",
    "    def _randomize_user(self, user_id, experiment):\n",
    "        # Get the hashset, which records a salt and the allocations.\n",
    "        experiment_hashset = hashes[experiment['salt']]\n",
    "        experiment_salt = experiment_hashset['salt']\n",
    "        experiment_allocation = experiment_hashset['current_buckets']\n",
    "        experiment_name = self._do_randomization(user_id, experiment_salt, experiment_allocation)\n",
    "        \n",
    "        if experiment_name != experiment['id']:\n",
    "            return 'noop'\n",
    "        \n",
    "        return self._do_randomization(user_id, experiment_name, experiments_sans_noop[experiment_name]['buckets'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Aside why do we have two hashes?* Sometimes, it's advantageous to reuse salts for multiple experiments. Having a double hash lets us ensure that even if we use the same part of a mod space for two experiments in two different time periods, the experiments remain randomized with respect to each other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Netflix Case\n",
    "------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Netflix takes a queue-based approach as described in their paper. Each experiment has a queue of assignmented that has been randomly sorted. In their paper, they say that each queue is of length 100, which means one can specify experiment allocations to nearest 1% (as opposed to the nearest 0.1% in the hashing system above). Allocating a flight for a user pops the latest assignment off the queue, assigns the user, and puts the assignment back on the end of the queue. \n",
    "\n",
    "Their system requires a bit of extra setup to maintain the queues, which we do below in `assignment_queues`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import random\n",
    "queue_depth = 100\n",
    "assignment_queues = {\n",
    "    'ChangeButton': {'q': ['blue'] * 25 + ['red'] * 25 + ['noop'] * 50, 'i': 0},\n",
    "    'ChangeLogo': {'q': ['stickfigure'] * 10 + ['professional'] * 10 + ['noop'] * 80, 'i': 0}\n",
    "}\n",
    "# randomize\n",
    "for k, v in assignment_queues.items():\n",
    "    random.shuffle(v['q'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class QueueRandomizer(BaseExperimentRandomizer):\n",
    "    \n",
    "    def _randomize_user(self, user_id, experiment):\n",
    "        queue = assignment_queues[experiment['id']]\n",
    "        current_value = queue['q'][queue['i']]\n",
    "        queue['i'] = (queue['i'] + 1) % queue_depth\n",
    "        \n",
    "        return current_value\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A similar check as above confirms that we're getting appropriately sized allocations. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Repeatability**\n",
    "\n",
    "Netflix's queues cycle, making them stateful. To remember which assignment was given to a user, one must store that information. Given the pervasive use of experiment allocations in the code base, this lookup needs to be fast and very high availability. This could be expensive in a system with potentially tens of millions in each of a hundred experiments. \n",
    "\n",
    "**Rampup and Shutdown**\n",
    "Experiment rampup (expanding exposure) and shutoff is also complicated because the user state needs to kept up to date (necessitating at least a call to see if the experiment is still live). \n",
    "\n",
    "**Exclusion**\n",
    "Exclusion is easy enough: simply stack two experiments in the same queue. Only one bucket from the combined experiment set will ever be assigned to a particular user. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Aside: exclusive experiments with dedicated controls* In my examples, I'm assuming two experiments that are set to be mutually exclusive have their own controls. This is wasteful: we would be assigning 35% of traffic in our toy example to control rather than the minimal requirement of 25%. There are optimizations that are possible, but one caveat is that it's easier to treat deal with separate controls in production when experiments rarely start and end at the same time. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "So far, it's unclear why to use a queue-based system since it requires adding a state storage problem to our workload.\n",
    "What about our statistical requirements? Does the queue-based system improve on hash-and-bucket?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Does a Hash-Based System Produce Reliable Randomization?\n",
    "--------------------------------------------------------\n",
    "\n",
    "Two requirements for statistical reliability are a balanced sample ratio and a correct distribution of statistics under the null hypothesis. \n",
    "\n",
    "The queue-based system obviously produces a balanced sample ratio: the maximum difference in user counts is 50 which occurs in an unrandomized queue that is halfway through the cycle. What about the hash and bucket system?\n",
    "\n",
    "**How to think about a balanced sample ratio**\n",
    "\n",
    "A/B testing creates a situation where the exposure of a user to a change is independent of any property of the user: selection bias is eliminated because ''selection\" of the treatment is a random effect. If our hash and bucket system is working correctly, we will get an event distribution of users into treatment and control, which we confirm with Pearson's Chi-Square Test.\n",
    "\n",
    "In the next code section, we produce 10000 random splits of 10000 users, and we show that in fact the splits are balanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def compute_histogram(assignments):\n",
    "    final_dict = Counter()\n",
    "    for a in assignments:\n",
    "        final_dict[a] += 1\n",
    "    return final_dict\n",
    "\n",
    "import numpy as np\n",
    "from scipy.stats import chisquare\n",
    "from uuid import uuid4\n",
    "num_users = 10000\n",
    "num_trials = 10000\n",
    "assumed_values = np.array([.25, .5, .25]) * num_users\n",
    "\n",
    "p_values = []\n",
    "all_values = []\n",
    "\n",
    "for i in range(num_trials):\n",
    "    users  = ({'locale': 'en-us', 'id': uuid4()} for u in range(num_users))\n",
    "    randomizer = HashAndBucketRandomizer()\n",
    "    assignment = [randomizer.assign_user(u, 'ChangeButton') for u in users]\n",
    "    assignment_hist = compute_histogram(assignment)\n",
    "    values = np.array([assignment_hist[k] for k in sorted(assignment_hist.keys())])  # blue, noop, red\n",
    "    all_values.append(values)\n",
    "    p_values.append(chisquare(values, assumed_values).pvalue)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x20e6ecd2ba8>]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAEACAYAAABVtcpZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x20e6dc9a6d8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot(sorted(p_values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distribution of treatments to controls follows a chi-square distribution, which implies that there is no *structural* imbalance between the count of treatments and the count of controls in my implementation. However, there is still *random* fluctuation: our worst imbalance in 10000 tries was TODO with a p-value of TODO. I argue that this doesn't matter. The important property of a randomization engine is that it produce two samples such that the probability of assignment is independent of any user property that could correlate with the outcome of interest. Consider the extreme case: let's say we use a biased coin to assign groups that turns up heads 55% of the time. Can we trust that the assignment is a random distribution? We can still get a he only thing that matters is that the coin bias not be correlated with anything else in the world. \n",
    "\n",
    "Since our randomizer isn't biased, one of the most important checks one can run at analysis time is a Sample Ratio Mismatch (SRM) check: always verify that the randomization engine is producing the expected sample ratio of treatments and controls. We've seen many cases of this failing due to misconfiguration, logging or cooking problems, or poorly designed experiment trigger conditions. Since we use a chi-square test to check for SRMs, so we run a slight risk of rejecting valid experimental results due to the natural false positive rate.\n",
    "\n",
    "This is a slight advantage to Netflix's queue system: there is no chance of an unnecessary rejection due to false positive rate in the sample ratio check. Since their distributions have a tight, absolute balance, one can easily verify that observed sample ratios meet the designation (though they still need to check!)\n",
    "\n",
    "There are three reasons why I don't think this is a big deal. \n",
    "\n",
    "1) True positives tend to be extreme. When we have identified true positive SRMs in the past, the p-value tended to be below a reasonable false positive rate (say, below 1e-5). This is due to the high statistical power associated with a chi-square test in an experiment with hundreds of thousands to millions of users.\n",
    "\n",
    "2) If a significant percentage of the user base is not new during experiment time, one can try multiple experiment-specific salts in the event of an SRM in pre-experiment data. In other words, I can efficiently reject salts that cause randomly low p-values in my SRM test prior to committing traffic to my experiment. (Caveat: make sure to verify post-hoc that your initial salt choices are maintaining a Chi-square distribution!) \n",
    "\n",
    "3) As Netflix describes, introducing stratification or a distributed queue tends to lead to a more \"spread\" in treatment/control counts since the perfect balance a queue guarantees only exists within a single queue. But again, this random fluctuation doesn't matter \n",
    "\n",
    "The second choice above doesn't work for experiments with new users, which is an important moment where Netflix and many other companies are particularly interested in experimentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Bonus: Seedfinder\n",
    "-----------------\n",
    "\n",
    "(TODO): make sure this is public information. I believe it's patented :)\n",
    "\n",
    "At Microsoft, we use the idea of trying multiple experiment-specific salts for another purpose. \n",
    "\n",
    "In fields where data points are expensive, experimentors use selection methods to lower variance. For instance, it's common to identify pairs of similar users then randomly assign one user in the pair to the treatment and one to control. TODO: source for this.\n",
    "\n",
    "Most of our products have a relatively stable user base week-over-week, so we can actually use pre-experiment data to \"pair\" our user base and randomly assign status within each pair. While that would be prohibitively expensive in the trillions of potential pairs in any experiment, we can approximate a paired study by trying multiple experiment-specific hashes until we find one that minimizes the difference between treatment and control over a set of pre-chosen metrics. In (TODO) Alex Deng and authors showed that this method improves power."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Stratification\n",
    "=============="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Netflix's paper spends a great deal of time explaining their stratification method. Functionally, stratification takes place in Neflix's system by using independent queues with one queue per stratum. Does a hash-and-bucket system allow for stratification? Of course! One simply assigns a unique salt to each stratum in the second hash step!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
